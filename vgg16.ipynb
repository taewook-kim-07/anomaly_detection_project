{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwAtboQjk0D4","executionInfo":{"status":"ok","timestamp":1664496775852,"user_tz":-540,"elapsed":9424,"user":{"displayName":"김규리","userId":"03329523788439339210"}},"outputId":"d0e7db2f-5305-40ba-c566-e4bf0349af26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!unzip -q \"/content/drive/MyDrive/manufacturing_bigdata/05.project01/02.outlier_classifier/outlier_train.zip\" -d \"/content/train\""],"metadata":{"id":"srB7lijhk9Nq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","import imgaug.augmenters as iaa\n","import imgaug as ia\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","#import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","\n","import albumentations as A\n","from collections import Counter\n","from keras import Input\n","from keras.models import Model\n","from keras import layers, models\n","from keras import optimizers, initializers, regularizers, metrics\n","from tensorflow.keras import optimizers\n","from glob import glob\n","from PIL import Image"],"metadata":{"id":"VWTgUH2HlHYA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#이미지 경로\n","\n","img_path = '/content/train/train/'"],"metadata":{"id":"OjeG9GYioq_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 크기\n","\n","IM_HEIGHT = 224\n","IM_WIDTH  = 224"],"metadata":{"id":"EEQQdQZ-pHeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# numpy 배열 출력시 가로로 길게 출력 되도록 설정\n","\n","np.set_printoptions(linewidth=100000)"],"metadata":{"id":"AnWel1kypmQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 프레임 로드\n","\n","df = pd.read_csv(\n","    \"/content/drive/MyDrive/manufacturing_bigdata/05.project01/02.outlier_classifier/train_df.csv\",\n","    index_col = 'index')"],"metadata":{"id":"RTzXtZQWpQoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"LkSmBUIrpVkV","colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"status":"ok","timestamp":1664496836900,"user_tz":-540,"elapsed":37,"user":{"displayName":"김규리","userId":"03329523788439339210"}},"outputId":"c1f56312-468f-4a57-fccb-aab38e965eec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       file_name       class state            label\n","index                                              \n","0      10000.png  transistor  good  transistor-good\n","1      10001.png     capsule  good     capsule-good\n","2      10002.png  transistor  good  transistor-good\n","3      10003.png        wood  good        wood-good\n","4      10004.png      bottle  good      bottle-good\n","...          ...         ...   ...              ...\n","4272   14272.png  transistor  good  transistor-good\n","4273   14273.png  transistor  good  transistor-good\n","4274   14274.png        grid  good        grid-good\n","4275   14275.png      zipper  good      zipper-good\n","4276   14276.png       screw  good       screw-good\n","\n","[4277 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-4b8fa909-a1da-458a-a5b1-7e54b901edc2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>class</th>\n","      <th>state</th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000.png</td>\n","      <td>transistor</td>\n","      <td>good</td>\n","      <td>transistor-good</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001.png</td>\n","      <td>capsule</td>\n","      <td>good</td>\n","      <td>capsule-good</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10002.png</td>\n","      <td>transistor</td>\n","      <td>good</td>\n","      <td>transistor-good</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10003.png</td>\n","      <td>wood</td>\n","      <td>good</td>\n","      <td>wood-good</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10004.png</td>\n","      <td>bottle</td>\n","      <td>good</td>\n","      <td>bottle-good</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4272</th>\n","      <td>14272.png</td>\n","      <td>transistor</td>\n","      <td>good</td>\n","      <td>transistor-good</td>\n","    </tr>\n","    <tr>\n","      <th>4273</th>\n","      <td>14273.png</td>\n","      <td>transistor</td>\n","      <td>good</td>\n","      <td>transistor-good</td>\n","    </tr>\n","    <tr>\n","      <th>4274</th>\n","      <td>14274.png</td>\n","      <td>grid</td>\n","      <td>good</td>\n","      <td>grid-good</td>\n","    </tr>\n","    <tr>\n","      <th>4275</th>\n","      <td>14275.png</td>\n","      <td>zipper</td>\n","      <td>good</td>\n","      <td>zipper-good</td>\n","    </tr>\n","    <tr>\n","      <th>4276</th>\n","      <td>14276.png</td>\n","      <td>screw</td>\n","      <td>good</td>\n","      <td>screw-good</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4277 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b8fa909-a1da-458a-a5b1-7e54b901edc2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b8fa909-a1da-458a-a5b1-7e54b901edc2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b8fa909-a1da-458a-a5b1-7e54b901edc2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# df[\"label\"].unique() : 중복을 제거하고 리턴\n","label_list = sorted(df['label'].unique())\n","\n","# label을 index 배열로 변환(클래스 분류를 하기 위해 index 마다 번호 부여)\n","df['label_int'] = df['label']\n","\n","# 인덱스는 num, 레이블은 label에 저장\n","# label_int 컬럼 레이블을 숫자로 변환\n","for num, label in enumerate(label_list):\n","    df[\"label_int\"].replace(label, num, inplace=True)"],"metadata":{"id":"P_1wR-Tspu_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label_int 컬럼의 빈도수 조회\n","# sort_index() : 인덱스로 정렬\n","\n","df[\"label_int\"].value_counts().sort_index()"],"metadata":{"id":"SGTa6fb6w1Qo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664496836902,"user_tz":-540,"elapsed":34,"user":{"displayName":"김규리","userId":"03329523788439339210"}},"outputId":"8d09f2d0-685b-49b1-e2e2-98d0310a79d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      10\n","1      11\n","2      11\n","3     209\n","4       7\n","     ... \n","83      8\n","84    240\n","85      9\n","86      9\n","87      8\n","Name: label_int, Length: 88, dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### 학습"],"metadata":{"id":"wlZ1SStwS5SG"}},{"cell_type":"code","source":["import cv2\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.utils import img_to_array\n","from tensorflow.keras.applications.vgg16 import decode_predictions\n","from tensorflow.keras.applications.vgg16 import preprocess_input"],"metadata":{"id":"uH9UFtm5987F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# VGG16 모델\n","\n","model = VGG16()"],"metadata":{"id":"CJLy_GPsB1DT","executionInfo":{"status":"ok","timestamp":1664496845078,"user_tz":-540,"elapsed":8202,"user":{"displayName":"김규리","userId":"03329523788439339210"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1a055fb-2473-4d50-9af9-cafdbb2c6f48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 3s 0us/step\n","553476096/553467096 [==============================] - 3s 0us/step\n"]}]},{"cell_type":"code","source":["df[\"label\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4B0-1mq5Wod","executionInfo":{"status":"ok","timestamp":1664496845079,"user_tz":-540,"elapsed":64,"user":{"displayName":"김규리","userId":"03329523788439339210"}},"outputId":"d817bc46-9afd-4364-82f8-8435f4b2cf57"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["index\n","0       transistor-good\n","1          capsule-good\n","2       transistor-good\n","3             wood-good\n","4           bottle-good\n","             ...       \n","4272    transistor-good\n","4273    transistor-good\n","4274          grid-good\n","4275        zipper-good\n","4276         screw-good\n","Name: label, Length: 4277, dtype: object"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["df[\"label\"].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"us99xCdl5bwR","executionInfo":{"status":"ok","timestamp":1664496845080,"user_tz":-540,"elapsed":61,"user":{"displayName":"김규리","userId":"03329523788439339210"}},"outputId":"dc775324-ea7d-4f73-8e8a-c58e9d4f1f16"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['transistor-good', 'capsule-good', 'wood-good', 'bottle-good', 'screw-good', 'cable-bent_wire', 'carpet-hole', 'hazelnut-good', 'pill-pill_type', 'cable-good', 'metal_nut-scratch', 'pill-good', 'screw-thread_side', 'zipper-fabric_border', 'leather-good', 'pill-scratch', 'toothbrush-good', 'hazelnut-crack', 'screw-manipulated_front', 'zipper-good', 'tile-good', 'carpet-good', 'metal_nut-good', 'bottle-contamination', 'grid-good', 'zipper-split_teeth', 'pill-crack', 'wood-combined', 'pill-color', 'screw-thread_top', 'cable-missing_cable', 'capsule-squeeze', 'zipper-rough', 'capsule-crack', 'capsule-poke', 'metal_nut-flip', 'carpet-metal_contamination', 'metal_nut-color', 'transistor-bent_lead', 'zipper-fabric_interior', 'leather-fold', 'tile-glue_strip', 'screw-scratch_neck', 'screw-scratch_head', 'hazelnut-cut', 'bottle-broken_large', 'bottle-broken_small', 'leather-cut', 'cable-cut_outer_insulation', 'zipper-squeezed_teeth', 'toothbrush-defective', 'cable-cut_inner_insulation', 'pill-contamination', 'cable-missing_wire', 'carpet-thread', 'grid-broken', 'pill-faulty_imprint', 'hazelnut-hole', 'leather-glue', 'leather-poke', 'transistor-damaged_case', 'wood-scratch', 'tile-gray_stroke', 'capsule-faulty_imprint', 'grid-glue', 'zipper-combined', 'carpet-color', 'grid-bent', 'pill-combined', 'hazelnut-print', 'cable-combined', 'capsule-scratch', 'metal_nut-bent', 'zipper-broken_teeth', 'tile-oil', 'transistor-misplaced', 'grid-thread', 'grid-metal_contamination', 'carpet-cut', 'wood-color', 'cable-cable_swap', 'tile-crack', 'leather-color', 'cable-poke_insulation', 'transistor-cut_lead', 'wood-hole', 'tile-rough', 'wood-liquid'], dtype=object)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["categories = df[\"label\"].unique()"],"metadata":{"id":"R1xza8u_7hQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_classes = len(categories)"],"metadata":{"id":"HeMB3TduMZ7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_classes"],"metadata":{"id":"XLa_kKxdMVop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664496845083,"user_tz":-540,"elapsed":55,"user":{"displayName":"김규리","userId":"03329523788439339210"}},"outputId":"132ff12a-96eb-4e5c-d35a-c6b9e3c1112e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["88"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# 이미지 크기 : 가로, 세로 224로 설정\n","\n","IM_HEIGHT = 224\n","IM_WIDTH = 224"],"metadata":{"id":"U5VGCUAF8BPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math"],"metadata":{"id":"lcEMki2d7V5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 전처리\n","\n","# X = []\n","# y = []\n","\n","# files = glob(img_path + \"/*.png\")\n","# print(\"files = \", files)\n","# print(\"=\"*100)\n","\n","# for i, f in enumerate(files):\n","#     img = Image.open(f)\n","#     img = img.convert(\"RGB\")\n","#     img = img.resize((IM_HEIGHT, IM_WIDTH))\n","#     data = np.asarray(img)\n","#     img.close\n","    \n","#     X.append(data)\n","#     y.append(label)"],"metadata":{"id":"9DNV-Y1S7zfk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 데이터와 테스트 데이터 분리\n","X_train, X_test, y_train, y_test = train_test_split(df['file_name'].tolist(),\n","                                                    df['label_int'].tolist(),\n","                                                    test_size = 0.1,\n","                                                    stratify = df['label_int'],\n","                                                    random_state = 152)"],"metadata":{"id":"Qh1h8x08x_ZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"id":"mpO9Tnx85-CB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"eZNpjOUj6BQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BI3rbpXuwame"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ia.seed(1)"],"metadata":{"id":"Tb8CS21DrQyN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_size = 224\n","batch_size = 256"],"metadata":{"id":"jMW6_8wjBRIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#학습 이미지 증강 객체\n","train_seq = iaa.Sequential([\n","    iaa.Resize({\"height\": image_size, \"width\": image_size}),\n","    iaa.Fliplr(0.5), # horizontal flips\n","    iaa.Crop(percent=(0, 0.1)), # random crops\n","    # Small gaussian blur with random sigma between 0 and 0.5.\n","    # But we only blur about 50% of all images.\n","    iaa.Sometimes(\n","        0.5,\n","        # Blur each image with varying strength using\n","        # gaussian blur (sigma between 0 and 3.0),\n","        # average/uniform blur (kernel size between 2x2 and 7x7)\n","        # median blur (kernel size between 3x3 and 11x11).\n","        iaa.OneOf([\n","            iaa.GaussianBlur((0, 3.0)),\n","            iaa.AverageBlur(k=(2, 7)),\n","            iaa.MedianBlur(k=(3, 11)),\n","            ]),\n","    ),\n","    iaa.Sometimes(\n","        0.3,\n","        #Either drop randomly 1 to 10% of all pixels (i.e. set\n","        # them to black) or drop them on an image with 2-5% percent\n","        # of the original size, leading to large dropped\n","        # rectangles.\n","        iaa.OneOf([\n","            iaa.Dropout((0.01, 0.1), per_channel=0.5),\n","            iaa.CoarseDropout(\n","                (0.03, 0.15), size_percent=(0.02, 0.05),\n","                per_channel=0.2\n","            ),\n","        ]),\n","    ),\n","    # crop some of the images by 0-10% of their height/width\n","    iaa.Sometimes(0.3 ,iaa.Crop(percent=(0, 0.1))),\n","    \n","    # Strengthen or weaken the contrast in each image.\n","    iaa.LinearContrast((0.75, 1.5)),\n","    # Add gaussian noise.\n","    # For 50% of all images, we sample the noise once per pixel.\n","    # For the other 50% of all images, we sample the noise per pixel AND\n","    # channel. This can change the color (not only brightness) of the\n","    # pixels.\n","    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n","    \n","    # Make some images brighter and some darker.\n","    # In 20% of all cases, we sample the multiplier once per channel,\n","    # which can end up changing the color of the images.\n","    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n","    # Apply affine transformations to each image.\n","    # Scale/zoom them, translate/move them, rotate them and shear them.\n","    iaa.Affine(\n","        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n","        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n","        rotate=(-25, 25),\n","        shear=(-8, 8)\n","    )\n","], random_order=True) # apply augmenters in random order"],"metadata":{"id":"cILZjYOGrRHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#테스트 이미지는 이미지 크기만 수정하고 다른 증강은 하지 않음\n","test_seq = iaa.Sequential([\n","    iaa.Resize({\"height\": image_size, \"width\": image_size})\n","], random_order=True) # apply augmenters in random order"],"metadata":{"id":"KmC8cukqrkN1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지를 증강시켜서 배치 사이즈 만큼씩 리턴하는 클래스 구현\n","\n","class  ImageSequence(tf.keras.utils.Sequence):\n","    # 객체 생성시 실행되는 함수\n","    # 매개변수\n","    # image_arr : 이미지가 저장된 배열\n","    # label_arr : 이미지의 종류가 저장된 배열\n","    # batch_size : 배치 사이즈 (한번에 리턴할 파일 개수)\n","    # seq : 이미지 증강 객체\n","\n","    def __init__(self, img_data_list ,label_int_list, batch_size, seq, img_path, total):\n","        # 매개변수들을 속성에 저장\n","        self.img_data_list  = img_data_list \n","        self.label_int_list = label_int_list\n","        self.batch_size = batch_size\n","        self.seq = seq\n","        self.img_path = img_path\n","        self.total = total\n","    \n","    # batch_size씩 이미지를 리턴했을때 전체 이미지를 리턴하려명 몆번 반복해야 하는지 리턴\n","    def __len__(self):\n","        \n","        # math.ceil : 소숫점 1자리 올림 예) 6.1 -> 7   6 -> 6   6.0 -> 6\n","\n","        # total 이미지의 개수 / batch_size (한번에 리턴할 이미지 개수) 의 올림을 리턴     \n","        return math.ceil(self.total / self.batch_size)\n","\n","    # 학습시 batch_size 씩 이미지를 리턴하는 함수로 텐서플로우에서 학습시 model 객체에서 자동으로 호출하는 함수\n","    # 매개변수 idx : 몆번째 batch 인지가 저장되는 매개변수 0부터 시작\n","    def __getitem__(self, idx):\n","        #리턴할 이미지를 저장할 리스트\n","        batch_img = []\n","        #리턴할 레이블을 저장할 리스트\n","        batch_label = []\n","        #idx에 저장된 몆번째 batch인지 저장된 숫자에 batch_size 곱함\n","        start_index = int(idx * self.batch_size)\n","        #idx에 저장된 몆번째 batch인지 저장된 숫자 + 1 에 batch_size 곱함\n","        end_index = int((idx +1)*self.batch_size )\n","\n","        #start_index 부터 end_index 까지 반복\n","        for index in range(start_index , end_index):\n","            #print(\"index = \", index)\n","            \n","            if index < self.total :\n","                # #이미지 파일명 저장            \n","                file_name = self.img_data_list[index]\n","                # #이미지를 읽어서 img에 저장\n","                img = cv2.imread(self.img_path + file_name)\n","                \n","                # #이미지를 읽지 못했다면\n","                if img is None:\n","                    #다음 이미지로 넘어감\n","                    continue\n","                # #이미지의 색상을 RGB 타입으로 변경\n","                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","                #이미지를 batch_img에 추가\n","                batch_img.append(img)\n","                #이미지 레이블을 batch_label에 추가\n","                batch_label.append(self.label_int_list[index])\n","                \n","        generate_img = None\n","        # batch_img를 증강시켜서 generate_img에 저장\n","        generate_img = self.seq(images=batch_img)\n","        #이미지를 float32타입으로 변환하고 255로 나눠줌        \n","        generate_img = np.array(generate_img, dtype=\"float32\") /255.0\n","         \n","        #INPUT_DIM (입력 레이블의 종류 88)\n","        # batch_label을 one hot encoding 함\n","        batch_label_arr = np.eye(88)[batch_label]\n","        #batch_label_arr을 float32 타입 변환\n","        batch_label_arr = np.array(batch_label_arr, dtype=\"float32\")\n","        \n","        #이미지와 레이블 리턴\n","        return generate_img,batch_label_arr"],"metadata":{"id":"5Ux6x_eqrmim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ImageSequence : 객체 생성\n","# X_train : 이미지\n","# y_train : 이미지 라벨\n","# batch_size : 배치 사이즈\n","# train_seq : 이미지 증강 객체\n","#img_path: 이미지 경로\n","#len(X_train) : 이미지 개수\n","train_sequence = ImageSequence(\n","    X_train,\n","    y_train,\n","    batch_size, \n","    train_seq,\n","    img_path,\n","    len(X_train))"],"metadata":{"id":"A_IgRcNmr6oi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ImageSequence : 객체 생성\n","# X_test : 이미지\n","# y_test : 이미지 라벨\n","# 32 : 배치 사이즈\n","# test_seq : 이미지 증강 객체 (테스트 데이터는 증강 하지 않고 이미지 크기만 설정)\n","#img_path: 이미지 경로\n","#len(X_test) : 이미지 개수\n","test_sequence = ImageSequence(\n","    X_test,\n","    y_test,\n","    batch_size, \n","    test_seq, \n","    img_path,\n","    len(X_test))"],"metadata":{"id":"0MpZLJa7sf7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications import VGG16"],"metadata":{"id":"MkjRBC_Z6TzK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# vgg16 모델 불러오기\n","pre_trained_vgg = VGG16(weights = 'imagenet',\n","                        include_top = False,\n","                        input_shape = (224, 224, 3))\n","pre_trained_vgg.trainable = False\n","pre_trained_vgg.summary()"],"metadata":{"id":"jVKvKaj1fX5_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664496846460,"user_tz":-540,"elapsed":957,"user":{"displayName":"김규리","userId":"03329523788439339210"}},"outputId":"941bcb21-5577-4896-b795-b2dce6dfd9c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","58900480/58889256 [==============================] - 0s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 0\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#vgg16 밑에 레이어 추가\n","additional_model = models.Sequential()\n","additional_model.add(pre_trained_vgg)\n","additional_model.add(layers.Flatten())\n","additional_model.add(layers.Dense(512, #kernel_regularizer = regularizers.l1_l2(l1=0.001,l2=0.001),\n","                                  activation='relu'))\n","additional_model.add(layers.Dropout(0.5))\n","additional_model.add(layers.Dense(256, #kernel_regularizer = regularizers.l1_l2(l1=0.001,l2=0.001),\n","                                  activation='relu'))\n","additional_model.add(layers.Dropout(0.5))\n","# additional_model.add(layers.Dense(64, kernel_regularizer = regularizers.l1_l2(l1=0.001,l2=0.001),activation='relu'))\n","# additional_model.add(layers.Dropout(0.5))\n","additional_model.add(layers.Dense(88, activation='softmax'))\n","\n","additional_model.compile(loss='categorical_crossentropy',\n","                         optimizer=optimizers.RMSprop(learning_rate=1e-4),\n","                         metrics=['acc'])"],"metadata":{"id":"4cMh9C5jvPrC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.utils import class_weight\n","class_weights = dict(\n","    zip(\n","        np.unique(y_train),\n","        class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n","    )\n",")\n","#class_weights"],"metadata":{"id":"Ka0QHqLfSDpq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scheduler(epoch: int, lr: float) -> float:\n","    if epoch != 0 and epoch % 15 == 0 and lr > 1e-6:\n","        return lr * 0.1\n","    # if epoch < 30:\n","    #     return 1e-3\n","    # elif epoch < 50:\n","    #     return 1e-4\n","    # elif epoch < 100:\n","    #     return 1e-5\n","    else:\n","        return lr\n","lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","early_stopping = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 30, restore_best_weights = True)\n","\n","checkpoint_filepath = \"/content/drive/MyDrive/best_model.h5\"\n","checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","    checkpoint_filepath,\n","    monitor=\"val_loss\",\n","    save_best_only=True,\n","    vervose=1,\n","    save_freq=\"epoch\"\n",")"],"metadata":{"id":"pEjEh6QqQBHL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습\n","history = additional_model.fit(train_sequence,\n","                               epochs=100, \n","                               validation_data=test_sequence,\n","                               class_weight = class_weights,\n","                               callbacks = [\n","                                            # early_stopping,\n","                                            checkpoint_callback,\n","                                            lr_scheduler_callback,\n","                                            ])"],"metadata":{"id":"_v-8gu49izJE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f34bd65f-6d48-484f-dabe-4e3c0fda7974"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","16/16 [==============================] - 319s 20s/step - loss: 4.7822 - acc: 0.0182 - val_loss: 4.2143 - val_acc: 0.1425 - lr: 1.0000e-04\n","Epoch 2/100\n","16/16 [==============================] - 274s 17s/step - loss: 4.5217 - acc: 0.0268 - val_loss: 4.1751 - val_acc: 0.0771 - lr: 1.0000e-04\n","Epoch 3/100\n","16/16 [==============================] - 332s 21s/step - loss: 4.4678 - acc: 0.0369 - val_loss: 4.0962 - val_acc: 0.1589 - lr: 1.0000e-04\n","Epoch 4/100\n","16/16 [==============================] - 298s 19s/step - loss: 4.3962 - acc: 0.0460 - val_loss: 3.9739 - val_acc: 0.1963 - lr: 1.0000e-04\n","Epoch 5/100\n","16/16 [==============================] - 271s 16s/step - loss: 4.3740 - acc: 0.0546 - val_loss: 3.8249 - val_acc: 0.2757 - lr: 1.0000e-04\n","Epoch 6/100\n","16/16 [==============================] - 309s 20s/step - loss: 4.2723 - acc: 0.0751 - val_loss: 3.7461 - val_acc: 0.2640 - lr: 1.0000e-04\n","Epoch 7/100\n","16/16 [==============================] - 345s 22s/step - loss: 4.2523 - acc: 0.0831 - val_loss: 3.6390 - val_acc: 0.3318 - lr: 1.0000e-04\n","Epoch 8/100\n","16/16 [==============================] - 325s 20s/step - loss: 4.2156 - acc: 0.0933 - val_loss: 3.5107 - val_acc: 0.3388 - lr: 1.0000e-04\n","Epoch 9/100\n","16/16 [==============================] - 291s 18s/step - loss: 4.1549 - acc: 0.1073 - val_loss: 3.3927 - val_acc: 0.3692 - lr: 1.0000e-04\n","Epoch 10/100\n","16/16 [==============================] - 312s 19s/step - loss: 4.0642 - acc: 0.1257 - val_loss: 3.2163 - val_acc: 0.4206 - lr: 1.0000e-04\n","Epoch 11/100\n","16/16 [==============================] - 305s 20s/step - loss: 4.0370 - acc: 0.1361 - val_loss: 3.1301 - val_acc: 0.4626 - lr: 1.0000e-04\n","Epoch 12/100\n","16/16 [==============================] - 257s 16s/step - loss: 3.9690 - acc: 0.1382 - val_loss: 3.0114 - val_acc: 0.3972 - lr: 1.0000e-04\n","Epoch 13/100\n","16/16 [==============================] - 322s 21s/step - loss: 3.8993 - acc: 0.1460 - val_loss: 2.9653 - val_acc: 0.4112 - lr: 1.0000e-04\n","Epoch 14/100\n","16/16 [==============================] - 296s 19s/step - loss: 3.8751 - acc: 0.1535 - val_loss: 2.8749 - val_acc: 0.3808 - lr: 1.0000e-04\n","Epoch 15/100\n","16/16 [==============================] - 339s 23s/step - loss: 3.7953 - acc: 0.1535 - val_loss: 2.8280 - val_acc: 0.3481 - lr: 1.0000e-04\n","Epoch 16/100\n","16/16 [==============================] - 358s 22s/step - loss: 3.7339 - acc: 0.1764 - val_loss: 2.8103 - val_acc: 0.3668 - lr: 1.0000e-05\n","Epoch 17/100\n","16/16 [==============================] - 278s 18s/step - loss: 3.7226 - acc: 0.1754 - val_loss: 2.7799 - val_acc: 0.3785 - lr: 1.0000e-05\n","Epoch 18/100\n","16/16 [==============================] - 271s 18s/step - loss: 3.7709 - acc: 0.1629 - val_loss: 2.7649 - val_acc: 0.3972 - lr: 1.0000e-05\n","Epoch 19/100\n","16/16 [==============================] - 311s 19s/step - loss: 3.6908 - acc: 0.1754 - val_loss: 2.7430 - val_acc: 0.4065 - lr: 1.0000e-05\n","Epoch 20/100\n"," 1/16 [>.............................] - ETA: 4:03 - loss: 3.6496 - acc: 0.2031"]}]},{"cell_type":"code","source":[],"metadata":{"id":"G0exwKm5W3A5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"cY5qOKjK_LdP"},"execution_count":null,"outputs":[]}]}